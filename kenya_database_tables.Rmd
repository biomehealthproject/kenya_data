---
title: "Database Tables Kenya"
author: "Fiona Spooner"
date: "July 30, 2019"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE,warning = FALSE)
```

```{r}
library(dplyr)
library(here)
library(lubridate)
library(knitr)
library(stringr)
library(taxize)
library(profvis)
library(jsonlite)

```


```{r}

all<-vroom::vroom(here::here("all_data_exif_out.csv"))

```


##Area Table

```{r}

sites<-all %>%
  select(Site.ID)%>%
  distinct()

sites$SiteName<-NULL
sites$SiteName[sites$Site.ID == "MN"]<- "Mara North"
sites$SiteName[sites$Site.ID == "MT"]<- "Mara Triangle"
sites$SiteName[sites$Site.ID == "NB"]<- "Naboisho"
sites$SiteName[sites$Site.ID == "OMC"]<- "Olare Motorogi Consrevancy"
sites$Country<-"Kenya"

colnames(sites)<-c("Area", "AreaName", "Country")

kable(sites)

#write.csv(sites, here::here("database/kenya_data/AreaTbl.csv"), row.names = FALSE)

```


##Location Table

```{r}

locs<-read.csv("CameraLocations.csv")

locs$coordSystem<-NULL
locs$coordSystem<-"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs "

locs$area<-NULL
locs$area[grepl("MN",locs$Location.ID)]<- "MN"
locs$area[grepl("MT",locs$Location.ID)]<- "MT"
locs$area[grepl("NB",locs$Location.ID)]<- "NB"
locs$area[grepl("OMC",locs$Location.ID)]<- "OMC"

colnames(locs)<-c("Location", "Latitude", "Longitude","CoordSystem","Area" )

locs$Country<-"Kenya"

kable(summary(locs))

#write.csv(locs, "LocationTbl.csv", row.names = FALSE)

#write.table(locs, "LocationTbl_no_head.csv", row.names = FALSE, col.names = FALSE, sep = ",")

```


##Field Season Table

```{r}

cam<-read.csv("CameraDateData.csv")
cam$Start_1<-as.Date(cam$Start_1, format = "%d-%m-%y")
cam$End_1<-as.Date(cam$End_1, format = "%d-%m-%y")

cam$Start_2<-as.Date(cam$Start_2, format = "%d-%m-%y")
cam$End_2<-as.Date(cam$End_2, format = "%d-%m-%y")

#cam[(cam$End_1 - cam$Start_1) >cam$No_Days_1,]

season<-data.frame("Kenya_1", year(cam$Start_1[1]),min(na.omit(cam$Start_1)),max(na.omit(cam$End_2)), nrow(cam), "Kenya")
colnames(season)<-c("Season", "Year", "StartDate", "EndDate", "NumCameras", "Country")

kable(season)

#write.csv(season, here::here("database/kenya_data/FieldSeasonTbl.csv"), row.names = FALSE)

```


#Sensor Table
```{r}
cam<-vroom::vroom("CameraDateData.csv")

cam_id<-cam %>% 
  select(Camera_ID) %>% 
  distinct()

cam_id$Date_Purchased<-as.Date("2015-01-01")
cam_id$Model<-"Snappy Snaps"
cam_id$Make<-"Trappy McTrapperson"
cam_id$Serial<-999999

colnames(cam_id)<-c("CameraID", "DatePurchased", "Model", "Make", "Serial")

#write.csv(cam_id, "SensorTbl.csv", row.names = FALSE)

#write.table(cam_id, "SensorTbl_no_head.csv", row.names = FALSE, col.names = FALSE, sep = ",")

```

## Deployment Table

```{r}

dep1<-cam[,1:5]   #picking out the location, camera, start, end and no days for each deployment
dep2<-cam[,c(1,2,7:9)]

names<-c("Location_ID", "Camera_ID", "Start", "End", "No_Days")
colnames(dep1)<-names
colnames(dep2)<-names

dep1$Deployment<-1 #1 for season .1 for deployment
dep2$Deployment<-2

dep<-rbind(dep1,dep2)

#dep$Country<-"Kenya"
dep$Season<-2018

dep<-dep[!is.na(dep$Start) & !is.na(dep$End),]

dep_out<-dep %>%
  group_by(Deployment, Season)%>%
  summarise(StartDate = min(na.omit(Start)), EndDate = max(na.omit(End)), NumCameras = n())

kable(dep_out)

#write.csv(dep_out, "DeploymentTbl.csv", row.names = FALSE)


```

## CT Study Table
```{r}

dep$Location_ID<-str_trim(as.character(dep$Location_ID))

dep$area<-NULL
dep$area[grepl("MN",dep$Location_ID)]<- "MN"
dep$area[grepl("MT",dep$Location_ID)]<- "MT"
dep$area[grepl("NB",dep$Location_ID)]<- "NB"
dep$area[grepl("OMC",dep$Location_ID)]<- "OMC"

dep$SensorType<-"CT"

dep$PersonDeploying<- "Emily Madsen"

colnames(dep)<-c("LocationID", "CameraID", "DateOn", "DateOff", "DaysDeployed","Deployment", "Season" ,"Area", "SensorType", "PersonDeploying")

kable(head(dep))

dep$DeploymentID<-paste(dep$LocationID, dep$Season, dep$Deployment, sep = "_")

write.csv(dep, "StudyTbl.csv", row.names = FALSE)

write.table(dep, "StudyTbl_no_head.csv", row.names = FALSE, col.names = FALSE, sep = ",")


```


```{r}
#all<-read.csv("all_data_exif_out.csv", stringsAsFactors = FALSE)

all<-vroom::vroom("all_data_exif_out.csv")

# all_ch<-all %>% 
#   filter(date > as.Date("2018-10-04") & date < as.Date("2018-11-20"))

all$Season<-NULL
all$Season<-ifelse(grepl("november",all$filepath ), "november", "october")

all$Site<-NULL
all$Site[all$Site.ID == "MN"]<-"mara_north"
all$Site[all$Site.ID == "MT"]<-"mara_triangle"
all$Site[all$Site.ID == "NB"]<-"naboisho"
all$Site[all$Site.ID == "OMC"]<-"omc"

all$IMG_Loc<-gsub("IMG","",all$image_no)
all$IMG_Loc<-paste0(all$Location.ID, all$IMG_Loc)

all$ID_uniqueAB<-paste0(all$Site, "/", all$Season, "/", all$site_cam, "/", all$IMG_Loc)
all$ID_uniqueAB<-gsub(".JPG","",all$ID_uniqueAB)
 

#not going to include the predictions based on snapshot serengeti so no need to merge in here
#all_exif<-merge(allimg, all, by = "ID_uniqueAB")   #some images missing - about 16000 - needs cleaning up after lunch

all$filepath<-gsub("\\\\","/",all$filepath)

```


```{r}
#fp<-read.csv("kenya_original_filepaths_working_filepaths.csv", stringsAsFactors = FALSE)
fp<-vroom::vroom("kenya_original_filepaths_working_filepaths_2019_10_18.csv", delim = ",")

fp$filepath<-gsub("//","/", fp$filepath)

all_exif_fp<-merge(fp, all, by = c("filepath","image_no"))

all_exif_fp$ImageID<-basename(all_exif_fp$new_file_structure)

sel_exif<-all_exif_fp%>%
  select(Site.ID,Site, Location.ID,Camera.ID,Season ,date,datetime,ImageID, new_file_structure)

colnames(sel_exif)<-c("SiteID", "Site", "LocationID", "CameraID", "Season", "Date", "DateTime","ImageID",  "FileLocation")




#Will probably need to change to a more general filepath at some point
#test<-gsub("M:/", "live.rd.ucl.ac.uk/ritd-ag-project-rd00lk-kejon62/", sel_exif$FileLocation[1])

###not sure where the duplications are coming from - needs investigating

#sel_exif_out<-sel_exif[!duplicated(sel_exif$ImageID),]

duplic<-sel_exif[duplicated(sel_exif$ImageID),]

duplic_rows<-sel_exif[sel_exif$ImageID %in% duplic$ImageID,]

no_duplic_rows<-sel_exif[!sel_exif$ImageID %in% duplic$ImageID,]

duplic_row_a<-duplic_rows %>% 
  group_by(ImageID) %>% 
  filter(Date == min(Date)) %>% 
  ungroup()

duplic_row_b<-duplic_rows %>% 
  group_by(ImageID) %>% 
  filter(Date == max(Date)) %>% 
  ungroup()

substring(duplic_row_b$ImageID, nchar(duplic_row_b$ImageID)-8, nchar(duplic_row_b$ImageID)-8) <- "1"


sel_exif<-rbind(no_duplic_rows, duplic_row_a, duplic_row_b)

#write.csv(sel_exif, "ImageTbl.csv", row.names = FALSE)

write.table(sel_exif, "ImageTbl_no_head.csv", row.names = FALSE, col.names = FALSE, sep = ",")

```

##Prediction Table

```{r}

allimg<-read.csv("kenya_ml_species_output_split_image.csv", stringsAsFactors = FALSE)
allimg$CamUniqueAB<-basename(dirname(allimg$IMG_ID))
allimg$IMG_NO<-basename(allimg$IMG_ID)

allimg$IMG_NO<-allimg$IMG_NO%>%
                    gsub("_0.JPG", "", .)%>%
                    gsub("_1.JPG", "", .)%>%
                  
    gsub("IMG", "", .)

allimg$CAM_IMG<-gsub("_CT.*","",allimg$CamUniqueAB)
allimg$CAM_IMG<-paste0(allimg$CAM_IMG, allimg$IMG_NO)


allimg$ID_uniqueAB<-paste0(allimg$Site,"/",allimg$Season,"/", allimg$CamUniqueAB, "/", allimg$CAM_IMG)
```


##Species Table

Using taxize to get taxonmic structure of each of the species found in kenya

```{r, eval=FALSE}
sp<-read.csv("species_codes.csv", stringsAsFactors = FALSE, header = FALSE, na.strings = FALSE)

sp<-sp[sp$V3 != "NA",]


common<-sp$V1
uids<-get_uid(sp$V3)

tax_out<-function(id){
  
  out<-classification(id,db = "ncbi")
  pause(3)
  sp_out<-out[[1]][out[[1]]$rank %in% c("kingdom", "phylum","class", "order", "family", "genus", "species"),]
  
  sp_out$kingdom<-sp_out$name[sp_out$rank == "kingdom"]
  sp_out$phylum<-sp_out$name[sp_out$rank == "phylum"]
  sp_out$class<-sp_out$name[sp_out$rank == "class"]
  sp_out$order<-sp_out$name[sp_out$rank == "order"]
  sp_out$family<-sp_out$name[sp_out$rank == "family"]
  sp_out$genus<-sp_out$name[sp_out$rank == "genus"]
  sp_out$species<-sp_out$name[sp_out$rank == "species"]
  
  sp_out<-sp_out %>% dplyr::select(kingdom, phylum, class, order, family, genus, species) %>% distinct()
  return(sp_out)

  }

taxon_out<-lapply(uids, tax_out)

taxon_df<-do.call(rbind,taxon_out)

taxon_df$COmmonName<-sp$V1
  
colnames(taxon_df)<-c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Binomial", "CommonName")

#write.csv(taxon_df, "SpeciesTbl.csv", row.names = FALSE)

#write.table(taxon_df, "SpeciesTbl_no_head.csv", row.names = FALSE, col.names = FALSE, sep = ",")

```


Tag Table

```{r}

jsf<-list.files(here::here("jsons"), full.names = TRUE, pattern = "*json")

json_extract<-function(json_file){
  
  jsin<-fromJSON(json_file) 
  ImageID<-jsin$asset$name
  TagID<-gsub("-asset.json", "",basename(json_file))
  
  json_loop_out<-NULL
  for (i in 1:nrow(jsin$regions)){
    
    CommonName<-as.character(jsin$regions$tags)[i]
    box_id<-jsin$regions$id[i]
    bl_x<-min(jsin$regions$points[[i]]$x)
    bl_y<-min(jsin$regions$points[[i]]$y)
    tr_x<-max(jsin$regions$points[[i]]$x)
    tr_y<-max(jsin$regions$points[[i]]$y)
    jlo_out<-data.frame(CommonName, box_id, bl_x, bl_y, tr_x, tr_y)
    json_loop_out<-rbind(json_loop_out, jlo_out)
  }
  
  TagID<-paste(TagID, json_loop_out$box_id, sep = "_")
  
  json_out<-data.frame(TagID = TagID, ImageID = ImageID, json_loop_out)
  print(json_file)
  return(json_out)
    }


json_df<-lapply(jsf,json_extract)

json_df_out<-do.call("rbind", json_df)


json_df_out$CommonName<-gsub("_"," ",json_df_out$CommonName)
json_df_out$CommonName<-gsub("[0-9]","",json_df_out$CommonName)
json_df_out$CommonName<-str_trim(json_df_out$CommonName)



#write.csv(json_df_out, "TaggingTbl.csv", row.names = FALSE)

write.table(json_df_out, "TaggingTbl_no_head.csv", row.names = FALSE, col.names = FALSE, sep = ",")

```